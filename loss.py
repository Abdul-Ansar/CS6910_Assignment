# -*- coding: utf-8 -*-
"""Loss.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DrtkOh4UgmrWRFzgUoRcBO5pm_DfKI5o
"""

import numpy as np

################################################
#         Loss
################################################

class CrossEntropy():
    """
    Class representing the cross-entropy loss function.
    """
    def __init__(self):
        """
        Constructor method for the cross-entropy loss function.
        """
        pass

    def calc_loss(self, t, y):
        """
        Method to calculate the cross-entropy loss.

        Args:
            t (numpy.ndarray): True labels.
            y (numpy.ndarray): Predicted probabilities.

        Returns:
            float: Cross-entropy loss.
        """
        self.t = t
        self.y = y
        loss = -np.sum(np.sum(self.t * np.log(self.y)))
        return loss

    def diff(self):
        """
        Method to calculate the gradient of the cross-entropy loss.

        Returns:
            numpy.ndarray: Gradient of the cross-entropy loss.
        """
        grad = -self.t / self.y
        return grad

class SquaredError():
    """
    Class representing the squared error loss function.
    """
    def __init__(self):
        """
        Constructor method for the squared error loss function.
        """
        pass

    def calc_loss(self, t, y):
        """
        Method to calculate the squared error loss.

        Args:
            t (numpy.ndarray): True labels.
            y (numpy.ndarray): Predicted values.

        Returns:
            float: Squared error loss.
        """
        self.t = t
        self.y = y
        loss = np.sum((t - y) ** 2)
        return loss

    def diff(self, t_batch, y_batch):
        """
        Method to calculate the gradient of the squared error loss.

        Args:
            t_batch (numpy.ndarray): True labels for the current batch.
            y_batch (numpy.ndarray): Predicted values for the current batch.

        Returns:
            numpy.ndarray: Gradient of the squared error loss.
        """
        grad = -(t_batch - y_batch)
        return grad